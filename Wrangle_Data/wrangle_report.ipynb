{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "Main aim of this project is to perform/learn how to wrangle data and visualize it. In order to achieve thata Twitter Data for  WeRateDoog will be used.\n",
    "\n",
    "Data wrangling will consist three part;\n",
    "\n",
    "* Gathering Data\n",
    "* Accesing Data\n",
    "* Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "## Gathering Data\n",
    "\n",
    "Gathering data process includes all the needed data for completing the project. And these are;\n",
    "\n",
    "* Twitter archieve which consists of WeRateDogs twitter archieve data.\n",
    "* Image prediction dataset which is is present in each tweet according to a neural network. And this dataset is downloaded by using Python request functionalities.\n",
    "* Json_tweet dataset is created to observe each tweets retweet counts, favorite counts etc. In order to get these, query Twitter API for each tweet's JSON data using Python's Tweepy library and store each tweet's entire set of JSON data in a file.\n",
    "\n",
    "## Assessing\n",
    "\n",
    "In previous part, Gathering Data, each dataset is obtained. And their basic characteristics is summarized.\n",
    "In Accesing Part, visualization of datasets will be performed. However, first I have created a merged_df dataset which includes three dataset. \n",
    "If needed, cleaning operations and quality issues will be identified in that part.\n",
    "\n",
    "Three datasets; tw, image_predict and tweet_info will be merge and then clean operation will be done.\n",
    "\n",
    "Before cleaning, observations from gathering & assesing part should be summarized. They will guide cleaning part step;\n",
    "\n",
    "\n",
    "> ### Issues\n",
    "\n",
    "> #### Quality Issues:\n",
    "\n",
    "> * Duplicated labels in tweet_id will be identified and removed.\n",
    "> * Required type conversion should be done. For example timestam should be in datetime format.\n",
    ">* jpg_url part will be identified, duplicated ones will be reduced.\n",
    "* name has None values or wrong values. That also be identified and reaaranged.\n",
    "* In several columns null objects are non-null. It requires None - NaN conversion.\n",
    "* One value in in_reply_to_user_id 4196984000 is repeated 47 times\n",
    "* Missing values in image_predict dataset.\n",
    "* Original ratings should be considered for analyzing.\n",
    "* Columns coming from image_predict dataset can be formed because all info may not be needed.\n",
    "* retweeted_status_id,  retweeted_status_user_id and retweeted_status_timestamp will be deleted because retweet count will be used only.\n",
    "* source has 3 types and tweets are sent from iPhone, WebClient and TweetDeck. We can make this column more readible by cleaning.\n",
    "* Dog gender will be predicted from text column.\n",
    "* A correctly cleaned rating_numerator column must be a float as numerator in some ratings contain decimals.\n",
    "\n",
    "> #### Tidiness Issues:\n",
    "\n",
    "> * Dog stage can be formed.\n",
    "> * Three dataset will be merged as a merged_df.\n",
    "\n",
    "\n",
    "\n",
    "## Cleaning\n",
    "\n",
    "Cleaning is performed according to issues stated in assesing part under Quality and Tidiness issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.plot.bar.html\n",
    "* https://pandas.pydata.org/pandas-docs/stable/merging.html\n",
    "* https://chrisalbon.com/python/data_wrangling/pandas_join_merge_dataframe/\n",
    "* https://github.com/tweepy/tweepy\n",
    "* http://support.gnip.com/articles/identifying-and-understanding-retweets.html\n",
    "* https://www.pythoncentral.io/introduction-to-tweepy-twitter-for-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
